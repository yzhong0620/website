[
  {
    "path": "capstones/Advanced Data Science/",
    "title": "Prediction of Health Outcomes Based on Various Environmental and Socioeconomic Factors",
    "description": "Advanced Data Science",
    "author": [
      {
        "name": "Yunyang Zhong",
        "url": {}
      }
    ],
    "date": "2021-12-14",
    "categories": [],
    "contents": "\r\n\r\n\r\nlibrary(tidyverse)         # for graphing and data cleaning\r\nlibrary(tidymodels)        # for modeling\r\nlibrary(stacks)            # for stacking models\r\nlibrary(naniar)            # for analyzing missing values\r\nlibrary(vip)               # for variable importance plots\r\nlibrary(usemodels)         # for tidymodels suggestions\r\nlibrary(xgboost)           # for boosting - need to install, don't need to load\r\nlibrary(doParallel)        # for parallel processing\r\nlibrary(lubridate)         # for dates\r\nlibrary(moderndive)        # for King County housing data\r\nlibrary(patchwork)         # for combining plots nicely\r\nlibrary(rmarkdown)         # for paged tables\r\nlibrary(shiny)             # for shiny dashboard\r\nlibrary(bslib)             # for theming\r\nlibrary(usmap)             # for maping\r\nlibrary(Metrics)           # for calculating metric\r\ntheme_set(theme_minimal()) # Lisa's favorite theme\r\n\r\n\r\n\r\nIntroduction\r\nThis project builds models to examine the relationship between various environmental and socioeconomic factors and health outcomes in California counties. A large portion of the project involved compiling the data from different publicly available sources, and some decisions on what to include and disclude were made based on the data that could be found. We ultimately chose to focus our analysis on California counties because of an abundance of publicly available data and included the years 2017, 2018, and 2019 because a variety of data had been collected in that time but were uninfluenced by the pandemic.\r\nWe built models predicting four different health outcomes - asthma, breast cancer, heart disease, and Alzheimer’s disease - but the dataset we created contains more than twenty other possible health outcomes standardized on a per person basis, making it easy for anyone to create their own.\r\nData Sources\r\nData for this project was collected from a wide variety of sources, most of which are available through the California Open Data Portal. Below is a list of data sources we used, each of which were standardized by population:\r\nDeath profiles by county - data on cause for each death in each county - California Health and Human Services\r\nCancer surgery counts by hospital - data was summarized at the county level for counts of surgeries performed for different types of cancers - California Health and Human Services\r\nAsthma emergency department visit rates by county - California Department of Public Health\r\nAir quality data by day - data was summarized to the county and annual level - US EPA\r\nCalifornia healthy places index - data on a variety of factors including tree canopy, average distance from a park, average distance from a supermarket, median income, and education level by county - Public Health Alliance of Southern California\r\nData Cleaning and Exploration\r\nBecause we combined data from 5 sources with 10+ datasets, our data cleaning process was complex and tedious. Instead of including all of them in this blog, here is a link to our GitHub repository, where all datasets and data cleaning files could be found.\r\nUse the interactive graphic below to explore the relationships between the predictors and outcomes in our dataset. If it doesn’t load, access it here.\r\n\r\n\r\nknitr::include_app(\"https://miarothberg.shinyapps.io/Final_Project/\", height = \"600px\")\r\n\r\n\r\n\r\n\r\n\r\nLiterature\r\nAsthma\r\nThere is an extensive body of research documenting the relationship between air pollution and asthma, which was the initial inspiration for this project. Increases in concentrations of particulate matter, sulfur dioxide, nitrogen dioxide, and ozone have been documented as directly correlated with increases in asthma-related emergency room visits. A general lack of air quality data led us to pursue other possible correlations, especially those provided by the healthy places index dataset.\r\nBreast Cancer\r\nRecent research has also revealed a positive correlation between those same air pollutants and breast cancer incidence rates. Variables such as education rate, income, and employment are also known to influence breast cancer prevalence, so were included in our model. Breast cancer has also been documented to be genetic, so we did not expect to be able to explain all variation in cancer rates by environmental and socioeconomic factors alone.\r\nAlzheimer’s Disease\r\nLong term exposure to air pollutants has been shown to contribute to cognitive decline in a variety of ways, including by increasing the risk of Alzheimer’s disease and hastening it’s onset. Maternal exposure to these pollutants has also been associated with increased risk of autism and ADHD, but we were unable to find data documenting those diagnoses.\r\nHeart Disease\r\nFinally, research using an EPA dataset has established that long-term exposure to particulate matter and nitrogen oxides at levels close to the National Ambient Air Quality Standards can prematurely age blood vessels and contribute to a more rapid buildup of calcium in the coronary artery, leading to heart disease.\r\nModeling Asthma ER Visits\r\n\r\n\r\npollution <- read.csv(\"data_standardized.csv\")\r\n\r\n\r\n\r\n\r\n\r\npollution %>% \r\n  select(where(is.numeric)) %>% \r\n  pivot_longer(cols = everything(),\r\n               names_to = \"variable\", \r\n               values_to = \"value\") %>% \r\n  ggplot(aes(x = value)) +\r\n  geom_histogram(bins = 30) +\r\n  facet_wrap(vars(variable), \r\n             scales = \"free\",\r\n             nrow = 5)\r\n\r\n\r\n\r\n\r\n\r\npollution %>% \r\n  select(asthma_er_avg) %>% \r\n  ggplot(aes(x = asthma_er_avg)) +\r\n  geom_histogram()\r\n\r\n\r\n\r\nfor(i in 1:ncol(pollution)) {\r\n  median <- median(pollution[,i],na.rm = TRUE)\r\n  for (j in 1:nrow(pollution)){\r\n    if (is.na(pollution[j, i])){\r\n      pollution[j, i] <- median\r\n    }\r\n  }\r\n}\r\n\r\n\r\n\r\nBased on the histogram above, we can see that asthma_er_avg is right_skewed. Also, to get rid of NA values without losing observations, we decided to replace all NAs with the median value of the column.\r\n\r\n\r\npollution_mod <- pollution %>%\r\n  mutate(log_asthma = log(asthma_er_avg, base = 10)) %>% \r\n  select(-asthma_er_avg) %>% \r\n  mutate(across(where(is.character), as.factor)) %>% \r\n  add_n_miss() %>% \r\n  filter(n_miss_all == 0) %>% \r\n  select(-n_miss_all)\r\n\r\nset.seed(456)\r\npollution_split <- initial_split(pollution_mod, prop = .75)\r\npollution_training <- training(pollution_split)\r\npollution_testing <- testing(pollution_split)\r\n\r\n\r\n\r\nTo fix to right-skewed shape, we performed a log transformation before using it as the outcome variable in models. We also made sure that all character variables are mutated to factor variables and reassured there were no more NAs.\r\nThe dataset has 153 observations of 64 variables in total. 75% (114 observations) were split to be in the training set and 25% (39 observations) were in the testing set.\r\nLasso Model\r\nIn modeling our data, we decided to look at five different machine learning techniques to determine the best model to predict the health outcomes due to environmental and socioeconomic models.\r\nLasso model uses both dimension reduction and variable selection in determining the best predictors for the outcomes. We preprocessed the data for the lasso model and removed some variables and normalized the rest of the predictors.\r\n\r\n\r\npollution_recipe <- recipe(log_asthma ~ ., data = pollution_training) %>% \r\n  step_rm(County,\r\n          Year,\r\n          All.causes..total.,\r\n          Alzheimer.s.disease,\r\n          Malignant.neoplasms,\r\n          Chronic.lower.respiratory.diseases,\r\n          Diabetes.mellitus,\r\n          Assault..homicide.,\r\n          Diseases.of.heart,\r\n          Essential.hypertension.and.hypertensive.renal.disease,\r\n          Accidents..unintentional.injuries.,\r\n          Chronic.liver.disease.and.cirrhosis,\r\n          Nephritis..nephrotic.syndrome.and.nephrosis,\r\n          Parkinson.s.disease,\r\n          Influenza.and.pneumonia,\r\n          Cerebrovascular.diseases,\r\n          Intentional.self.harm..suicide.,\r\n          FIPS,\r\n          cancer_incidence_rate,\r\n          asthma_deaths,\r\n          Bladder_Surgery_Ct,\r\n          Brain_Surgery_Ct,\r\n          Breast_Surgery_Ct,\r\n          Colon_Surgery_Ct,\r\n          Esophagus_Surgery_Ct,\r\n          Liver_Surgery_Ct,\r\n          Lung_Surgery_Ct,\r\n          Pancreas_Surgery_Ct,\r\n          Prostate_Surgery_Ct,\r\n          Rectum_Surgery_Ct,\r\n          Stomach_Surgery_Ct) %>% \r\n  step_normalize(all_predictors(), \r\n                 -all_nominal()) %>% \r\n  step_dummy(all_nominal(), \r\n             -all_outcomes())\r\n\r\n\r\n\r\nThen applied it to our training data.\r\n\r\n\r\npollution_recipe %>% \r\n  prep(pollution_training) %>%\r\n  juice()\r\n\r\n\r\n# A tibble: 114 x 33\r\n   annual_mean_pm25 annual_mean_ozone annual_mean_pb annual_mean_pm10\r\n              <dbl>             <dbl>          <dbl>            <dbl>\r\n 1           0.769             1.91           -0.438           1.20  \r\n 2          -0.791            -0.0862         -0.176          -0.426 \r\n 3           0.0376           -0.153          -0.176           0.136 \r\n 4           0.130            -0.118          -0.176           0.0213\r\n 5          -0.851             0.0999         -0.969          -0.949 \r\n 6          -0.625            -0.107          -0.860          -0.442 \r\n 7           0.861            -0.0905         -0.176          -0.150 \r\n 8           1.70              0.645          -0.176          -1.08  \r\n 9          -1.25             -1.03           -0.176          -0.150 \r\n10           3.09             -0.0905         -0.176          -0.150 \r\n# ... with 104 more rows, and 29 more variables:\r\n#   annual_mean_co <dbl>, annual_mean_no2 <dbl>,\r\n#   annual_mean_so2 <dbl>, hpi2score <dbl>, economic <dbl>,\r\n#   education <dbl>, housing <dbl>, healthcareaccess <dbl>,\r\n#   neighborhood <dbl>, pollution <dbl>, transportation <dbl>,\r\n#   social <dbl>, insured <dbl>, uncrowded <dbl>,\r\n#   homeownership <dbl>, automobile <dbl>, commute <dbl>, ...\r\n\r\nTo define the model we chose linear regression and other arguments to fit the model.\r\n\r\n\r\npollution_lasso_mod <- \r\n  linear_reg(mixture = 1) %>% \r\n  set_engine(\"glmnet\") %>% \r\n  set_args(penalty = tune()) %>% \r\n  set_mode(\"regression\")\r\n\r\n\r\n\r\nWe then created a workflow with our recipe and defined model.\r\n\r\n\r\npollution_lasso_wf <- \r\n  workflow() %>% \r\n  add_recipe(pollution_recipe) %>% \r\n  add_model(pollution_lasso_mod)\r\n\r\n\r\n\r\n\r\n\r\npenalty_grid <- grid_regular(penalty(),\r\n                             levels = 20)\r\npenalty_grid \r\n\r\n\r\n# A tibble: 20 x 1\r\n    penalty\r\n      <dbl>\r\n 1 1   e-10\r\n 2 3.36e-10\r\n 3 1.13e- 9\r\n 4 3.79e- 9\r\n 5 1.27e- 8\r\n 6 4.28e- 8\r\n 7 1.44e- 7\r\n 8 4.83e- 7\r\n 9 1.62e- 6\r\n10 5.46e- 6\r\n11 1.83e- 5\r\n12 6.16e- 5\r\n13 2.07e- 4\r\n14 6.95e- 4\r\n15 2.34e- 3\r\n16 7.85e- 3\r\n17 2.64e- 2\r\n18 8.86e- 2\r\n19 2.98e- 1\r\n20 1   e+ 0\r\n\r\nWe then tuned the model using a penalty grid and determined our number of resamples.\r\n\r\n\r\nctrl_grid <- control_stack_grid()\r\n\r\nset.seed(456)\r\npollution_cv <- vfold_cv(pollution_training, v = 5)\r\n\r\npollution_lasso_tune <- \r\n  pollution_lasso_wf %>% \r\n  tune_grid(\r\n    resamples = pollution_cv,\r\n    grid = penalty_grid,\r\n    control = ctrl_grid\r\n    )\r\n\r\npollution_lasso_tune\r\n\r\n\r\n# Tuning results\r\n# 5-fold cross-validation \r\n# A tibble: 5 x 5\r\n  splits          id    .metrics          .notes       .predictions   \r\n  <list>          <chr> <list>            <list>       <list>         \r\n1 <split [91/23]> Fold1 <tibble [40 x 5]> <tibble [1 ~ <tibble [460 x~\r\n2 <split [91/23]> Fold2 <tibble [40 x 5]> <tibble [1 ~ <tibble [460 x~\r\n3 <split [91/23]> Fold3 <tibble [40 x 5]> <tibble [1 ~ <tibble [460 x~\r\n4 <split [91/23]> Fold4 <tibble [40 x 5]> <tibble [1 ~ <tibble [460 x~\r\n5 <split [92/22]> Fold5 <tibble [40 x 5]> <tibble [1 ~ <tibble [440 x~\r\n\r\nLooked at the RMSE of the model output to determine the best model to use on the testing data.\r\n\r\n\r\npollution_lasso_tune %>% \r\n  select(id, .metrics) %>% \r\n  unnest(.metrics) %>% \r\n  filter(.metric == \"rmse\")\r\n\r\n\r\n# A tibble: 100 x 6\r\n   id     penalty .metric .estimator .estimate .config              \r\n   <chr>    <dbl> <chr>   <chr>          <dbl> <chr>                \r\n 1 Fold1 1   e-10 rmse    standard       0.232 Preprocessor1_Model01\r\n 2 Fold1 3.36e-10 rmse    standard       0.232 Preprocessor1_Model02\r\n 3 Fold1 1.13e- 9 rmse    standard       0.232 Preprocessor1_Model03\r\n 4 Fold1 3.79e- 9 rmse    standard       0.232 Preprocessor1_Model04\r\n 5 Fold1 1.27e- 8 rmse    standard       0.232 Preprocessor1_Model05\r\n 6 Fold1 4.28e- 8 rmse    standard       0.232 Preprocessor1_Model06\r\n 7 Fold1 1.44e- 7 rmse    standard       0.232 Preprocessor1_Model07\r\n 8 Fold1 4.83e- 7 rmse    standard       0.232 Preprocessor1_Model08\r\n 9 Fold1 1.62e- 6 rmse    standard       0.232 Preprocessor1_Model09\r\n10 Fold1 5.46e- 6 rmse    standard       0.232 Preprocessor1_Model10\r\n# ... with 90 more rows\r\n\r\nWe then visualized the RMSE as a function of the penalty value.\r\n\r\n\r\npollution_lasso_tune %>% \r\n  collect_metrics() %>% \r\n  filter(.metric == \"rmse\") %>% \r\n  ggplot(aes(x = penalty, y = mean)) +\r\n  geom_point() +\r\n  geom_line() +\r\n  scale_x_log10(\r\n   breaks = scales::trans_breaks(\"log10\", function(x) 10^x),\r\n   labels = scales::trans_format(\"log10\",scales::math_format(10^.x))) +\r\n  labs(x = \"penalty\", y = \"rmse\")\r\n\r\n\r\n\r\n\r\nWe used the show_best() and select_best() functions to select the best model.\r\n\r\n\r\npollution_lasso_tune %>% \r\n  show_best(metric = \"rmse\")\r\n\r\n\r\n# A tibble: 5 x 7\r\n   penalty .metric .estimator  mean     n std_err .config             \r\n     <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \r\n1 0.00785  rmse    standard   0.282     5  0.0127 Preprocessor1_Model~\r\n2 0.00234  rmse    standard   0.302     5  0.0147 Preprocessor1_Model~\r\n3 0.0264   rmse    standard   0.328     5  0.0154 Preprocessor1_Model~\r\n4 0.000695 rmse    standard   0.336     5  0.0344 Preprocessor1_Model~\r\n5 0.000207 rmse    standard   0.346     5  0.0440 Preprocessor1_Model~\r\n\r\n\r\n\r\nbest_param <- pollution_lasso_tune %>% \r\n  select_best(metric = \"rmse\")\r\nbest_param\r\n\r\n\r\n# A tibble: 1 x 2\r\n  penalty .config              \r\n    <dbl> <chr>                \r\n1 0.00785 Preprocessor1_Model16\r\n\r\n\r\n\r\none_se_param <- pollution_lasso_tune %>% \r\n  select_by_one_std_err(metric = \"rmse\", desc(penalty))\r\none_se_param\r\n\r\n\r\n# A tibble: 1 x 9\r\n  penalty .metric .estimator  mean     n std_err .config  .best .bound\r\n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>    <dbl>  <dbl>\r\n1 0.00785 rmse    standard   0.282     5  0.0127 Preproc~ 0.282  0.295\r\n\r\nWe then finalized the workflow using the selected lasso model.\r\n\r\n\r\npollution_lasso_final_wf <- pollution_lasso_wf %>% \r\n  finalize_workflow(one_se_param)\r\npollution_lasso_final_wf\r\n\r\n\r\n== Workflow ==========================================================\r\nPreprocessor: Recipe\r\nModel: linear_reg()\r\n\r\n-- Preprocessor ------------------------------------------------------\r\n3 Recipe Steps\r\n\r\n* step_rm()\r\n* step_normalize()\r\n* step_dummy()\r\n\r\n-- Model -------------------------------------------------------------\r\nLinear Regression Model Specification (regression)\r\n\r\nMain Arguments:\r\n  penalty = 0.00784759970351461\r\n  mixture = 1\r\n\r\nComputational engine: glmnet \r\n\r\nUsing this finalized workflow, we fit the data to the training data and visualized the estimate values.\r\n\r\n\r\npollution_lasso_final_mod <- pollution_lasso_final_wf %>% \r\n  fit(data = pollution_training)\r\n\r\npollution_lasso_final_mod %>% \r\n  pull_workflow_fit() %>% \r\n  tidy() \r\n\r\n\r\n# A tibble: 33 x 3\r\n   term              estimate penalty\r\n   <chr>                <dbl>   <dbl>\r\n 1 (Intercept)        2.97    0.00785\r\n 2 annual_mean_pm25   0       0.00785\r\n 3 annual_mean_ozone  0.00160 0.00785\r\n 4 annual_mean_pb     0.0210  0.00785\r\n 5 annual_mean_pm10  -0.161   0.00785\r\n 6 annual_mean_co     0.0539  0.00785\r\n 7 annual_mean_no2   -0.132   0.00785\r\n 8 annual_mean_so2    0.0652  0.00785\r\n 9 hpi2score          0       0.00785\r\n10 economic           0       0.00785\r\n# ... with 23 more rows\r\n\r\nWe then looked at the evaluation metrics across all folds.\r\n\r\n\r\npollution_lasso_test <- pollution_lasso_final_wf %>% \r\n  last_fit(pollution_split)\r\n\r\n# Metrics for model applied to test data\r\npollution_lasso_test %>% \r\n  collect_metrics()\r\n\r\n\r\n# A tibble: 2 x 4\r\n  .metric .estimator .estimate .config             \r\n  <chr>   <chr>          <dbl> <chr>               \r\n1 rmse    standard       0.267 Preprocessor1_Model1\r\n2 rsq     standard       0.846 Preprocessor1_Model1\r\n\r\nXgboost model\r\nFirst we used the use_xgboost() function, which gives recommendation on how to build our recipe, workflow, etc.\r\n\r\n\r\nuse_xgboost(log_asthma ~ ., data = pollution_training)\r\n\r\n\r\nxgboost_recipe <- \r\n  recipe(formula = log_asthma ~ ., data = pollution_training) %>% \r\n  step_novel(all_nominal(), -all_outcomes()) %>% \r\n  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>% \r\n  step_zv(all_predictors()) \r\n\r\nxgboost_spec <- \r\n  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), \r\n    loss_reduction = tune(), sample_size = tune()) %>% \r\n  set_mode(\"regression\") %>% \r\n  set_engine(\"xgboost\") \r\n\r\nxgboost_workflow <- \r\n  workflow() %>% \r\n  add_recipe(xgboost_recipe) %>% \r\n  add_model(xgboost_spec) \r\n\r\nset.seed(90624)\r\nxgboost_tune <-\r\n  tune_grid(xgboost_workflow, resamples = stop(\"add your rsample object\"), grid = stop(\"add number of candidate points\"))\r\n\r\nBased on output from the use_xgboost() function and our previous recipes, we created our own recipe.\r\n\r\n\r\nboost_recipe <- \r\n  recipe(formula = log_asthma ~ ., data = pollution_training) %>% \r\n  step_rm(County,\r\n          Year,\r\n          All.causes..total.,\r\n          Alzheimer.s.disease,\r\n          Malignant.neoplasms,\r\n          Chronic.lower.respiratory.diseases,\r\n          Diabetes.mellitus,\r\n          Assault..homicide.,\r\n          Diseases.of.heart,\r\n          Essential.hypertension.and.hypertensive.renal.disease,\r\n          Accidents..unintentional.injuries.,\r\n          Chronic.liver.disease.and.cirrhosis,\r\n          Nephritis..nephrotic.syndrome.and.nephrosis,\r\n          Parkinson.s.disease,\r\n          Influenza.and.pneumonia,\r\n          Cerebrovascular.diseases,\r\n          Intentional.self.harm..suicide.,\r\n          FIPS,\r\n          cancer_incidence_rate,\r\n          asthma_deaths,\r\n          Bladder_Surgery_Ct,\r\n          Brain_Surgery_Ct,\r\n          Breast_Surgery_Ct,\r\n          Colon_Surgery_Ct,\r\n          Esophagus_Surgery_Ct,\r\n          Liver_Surgery_Ct,\r\n          Lung_Surgery_Ct,\r\n          Pancreas_Surgery_Ct,\r\n          Prostate_Surgery_Ct,\r\n          Rectum_Surgery_Ct,\r\n          Stomach_Surgery_Ct) %>% \r\n  step_novel(all_nominal_predictors()) %>% \r\n  step_dummy(all_nominal_predictors(), one_hot = TRUE)  %>% \r\n  step_zv(all_predictors()) %>% \r\n  step_normalize(all_predictors(), \r\n                 -all_nominal())\r\n\r\n\r\n\r\nNext, we specified the model. learn_rate is the parameter we decided to tune, and we created a grid of 10 values to try in tuning for learn_rate as the following:\r\n\r\n\r\nboost_spec <- boost_tree(\r\n  trees = 1000,            # number of trees, T in the equations above\r\n  tree_depth = 2,          # max number of splits in the tree\r\n  min_n = 5,               # min points required for node to be further split\r\n  loss_reduction = 10^-5,  # when to stop - smaller = more since it only has to get a little bit better \r\n  sample_size = 1,         # proportion of training data to use\r\n  learn_rate = tune(),     # lambda from the equations above\r\n  stop_iter = 50           # number of iterations w/o improvement b4 stopping\r\n) %>% \r\n  set_engine(\"xgboost\", colsample_bytree = 1) %>% \r\n  set_mode(\"regression\")\r\n\r\n\r\n\r\n\r\n\r\nboost_grid <- grid_regular(learn_rate(),\r\n                           levels = 10)\r\nboost_grid\r\n\r\n\r\n# A tibble: 10 x 1\r\n     learn_rate\r\n          <dbl>\r\n 1 0.0000000001\r\n 2 0.000000001 \r\n 3 0.00000001  \r\n 4 0.0000001   \r\n 5 0.000001    \r\n 6 0.00001     \r\n 7 0.0001      \r\n 8 0.001       \r\n 9 0.01        \r\n10 0.1         \r\n\r\nWe then put the recipe and model specification into a workflow.\r\n\r\n\r\nboost_wf <- workflow() %>% \r\n  add_recipe(boost_recipe) %>%\r\n  add_model(boost_spec) \r\n\r\n\r\n\r\nThe next step is to train these models. registerDoParallel() was used to speed up the process.\r\n\r\n\r\nset.seed(456)\r\nregisterDoParallel()\r\n\r\nboost_tune <- boost_wf %>% \r\n  tune_grid(\r\n  # resamples = val_split,\r\n  resamples = pollution_cv,\r\n  grid = boost_grid,\r\n  control = ctrl_grid\r\n)\r\n\r\n\r\n\r\nHere is a table summarizing the results. We can see that larger learning rates actually seem to do better.\r\n\r\n\r\ncollect_metrics(boost_tune)\r\n\r\n\r\n# A tibble: 20 x 7\r\n     learn_rate .metric .estimator     mean     n std_err .config     \r\n          <dbl> <chr>   <chr>         <dbl> <int>   <dbl> <chr>       \r\n 1 0.0000000001 rmse    standard     2.57       5  0.0333 Preprocesso~\r\n 2 0.0000000001 rsq     standard   NaN          0 NA      Preprocesso~\r\n 3 0.000000001  rmse    standard     2.57       5  0.0333 Preprocesso~\r\n 4 0.000000001  rsq     standard   NaN          0 NA      Preprocesso~\r\n 5 0.00000001   rmse    standard     2.57       5  0.0333 Preprocesso~\r\n 6 0.00000001   rsq     standard     0.0589     1 NA      Preprocesso~\r\n 7 0.0000001    rmse    standard     2.57       5  0.0333 Preprocesso~\r\n 8 0.0000001    rsq     standard     0.741      5  0.0486 Preprocesso~\r\n 9 0.000001     rmse    standard     2.57       5  0.0333 Preprocesso~\r\n10 0.000001     rsq     standard     0.751      5  0.0511 Preprocesso~\r\n11 0.00001      rmse    standard     2.55       5  0.0333 Preprocesso~\r\n12 0.00001      rsq     standard     0.746      5  0.0603 Preprocesso~\r\n13 0.0001       rmse    standard     2.34       5  0.0340 Preprocesso~\r\n14 0.0001       rsq     standard     0.764      5  0.0594 Preprocesso~\r\n15 0.001        rmse    standard     1.09       5  0.0382 Preprocesso~\r\n16 0.001        rsq     standard     0.800      5  0.0569 Preprocesso~\r\n17 0.01         rmse    standard     0.217      5  0.0187 Preprocesso~\r\n18 0.01         rsq     standard     0.915      5  0.0377 Preprocesso~\r\n19 0.1          rmse    standard     0.134      5  0.0130 Preprocesso~\r\n20 0.1          rsq     standard     0.959      5  0.0155 Preprocesso~\r\n\r\nWe also plotted the rmse to visually support our conclusion above.\r\n\r\n\r\ncollect_metrics(boost_tune) %>% \r\n  filter(.metric == \"rmse\") %>% \r\n  ggplot(aes(x = learn_rate, y = mean)) +\r\n  geom_point() +\r\n  geom_line() +\r\n  scale_x_log10() +\r\n  labs(y = \"rmse\") +\r\n  theme_minimal()\r\n\r\n\r\n\r\n\r\nThen we decided to select the best learning rate parameter and finalize the model.\r\n\r\n\r\nbest_lr <- select_best(boost_tune, \"rmse\")\r\nbest_lr\r\n\r\n\r\n# A tibble: 1 x 2\r\n  learn_rate .config              \r\n       <dbl> <chr>                \r\n1        0.1 Preprocessor1_Model10\r\n\r\n\r\n\r\n# finalize workflow\r\nfinal_boost_wf <- finalize_workflow(\r\n  boost_wf,\r\n  best_lr\r\n)\r\n\r\n# fit final\r\nfinal_boost <- final_boost_wf %>% \r\n  fit(data = pollution_training)\r\n\r\n\r\n\r\nThis graph tells us which predictors are the most important. It seems that supermarkets, annual_mean_no2, and homeownership have the largest influence on asthma ER visit.\r\n\r\n\r\nfinal_boost %>% \r\n  pull_workflow_fit() %>%\r\n  vip(geom = \"col\")\r\n\r\n\r\n\r\n\r\nThe final model was also fitted to the testing data. We can see the testing rmse is 0.05, larger than the training rmse.\r\n\r\n\r\n# Use model on test data\r\ntest_preds <- pollution_testing %>% \r\n  bind_cols(predict(final_boost, new_data = pollution_testing)) \r\n\r\n# Compute test rmse\r\ntest_preds %>% \r\n  summarize(rmse = sqrt(mean((log_asthma - .pred)^2))) %>% \r\n  pull(rmse)\r\n\r\n\r\n[1] 0.05400519\r\n\r\nThe graph below visualized the results. We can conclude that the predicted values are very close to the actual values.\r\n\r\n\r\n# Graph results\r\ntest_preds %>% \r\n  ggplot(aes(x = log_asthma,\r\n             y = .pred)) +\r\n  geom_point(alpha = .5, \r\n             size = .5) +\r\n  geom_smooth(se = FALSE) +\r\n  geom_abline(slope = 1, \r\n              intercept = 0, \r\n              color = \"darkred\") +\r\n  labs(x = \"Actual log(asthma)\", \r\n       y = \"Predicted log(asthma)\")\r\n\r\n\r\n\r\n\r\nRandom Forest Model\r\nWe set up the random forest model with its recipe and preprocessing steps.\r\n\r\n\r\npollution_rfrecipe <- recipe(log_asthma ~ ., data = pollution_training) %>% \r\n  step_rm(County,\r\n          Year,\r\n          All.causes..total.,\r\n          Alzheimer.s.disease,\r\n          Malignant.neoplasms,\r\n          Chronic.lower.respiratory.diseases,\r\n          Diabetes.mellitus,\r\n          Assault..homicide.,\r\n          Diseases.of.heart,\r\n          Essential.hypertension.and.hypertensive.renal.disease,\r\n          Accidents..unintentional.injuries.,\r\n          Chronic.liver.disease.and.cirrhosis,\r\n          Nephritis..nephrotic.syndrome.and.nephrosis,\r\n          Parkinson.s.disease,\r\n          Influenza.and.pneumonia,\r\n          Cerebrovascular.diseases,\r\n          Intentional.self.harm..suicide.,\r\n          FIPS,\r\n          cancer_incidence_rate,\r\n          asthma_deaths,\r\n          Bladder_Surgery_Ct,\r\n          Brain_Surgery_Ct,\r\n          Breast_Surgery_Ct,\r\n          Colon_Surgery_Ct,\r\n          Esophagus_Surgery_Ct,\r\n          Liver_Surgery_Ct,\r\n          Lung_Surgery_Ct,\r\n          Pancreas_Surgery_Ct,\r\n          Prostate_Surgery_Ct,\r\n          Rectum_Surgery_Ct,\r\n          Stomach_Surgery_Ct) %>% \r\n  step_normalize(all_predictors(), \r\n                 -all_nominal()) %>% \r\n  step_dummy(all_nominal(), \r\n             -all_outcomes())\r\n\r\n\r\n\r\nApplied the recipe to the training data.\r\n\r\n\r\npollution_rfrecipe %>% \r\n  prep(pollution_training) %>%\r\n  juice()\r\n\r\n\r\n# A tibble: 114 x 33\r\n   annual_mean_pm25 annual_mean_ozone annual_mean_pb annual_mean_pm10\r\n              <dbl>             <dbl>          <dbl>            <dbl>\r\n 1           0.769             1.91           -0.438           1.20  \r\n 2          -0.791            -0.0862         -0.176          -0.426 \r\n 3           0.0376           -0.153          -0.176           0.136 \r\n 4           0.130            -0.118          -0.176           0.0213\r\n 5          -0.851             0.0999         -0.969          -0.949 \r\n 6          -0.625            -0.107          -0.860          -0.442 \r\n 7           0.861            -0.0905         -0.176          -0.150 \r\n 8           1.70              0.645          -0.176          -1.08  \r\n 9          -1.25             -1.03           -0.176          -0.150 \r\n10           3.09             -0.0905         -0.176          -0.150 \r\n# ... with 104 more rows, and 29 more variables:\r\n#   annual_mean_co <dbl>, annual_mean_no2 <dbl>,\r\n#   annual_mean_so2 <dbl>, hpi2score <dbl>, economic <dbl>,\r\n#   education <dbl>, housing <dbl>, healthcareaccess <dbl>,\r\n#   neighborhood <dbl>, pollution <dbl>, transportation <dbl>,\r\n#   social <dbl>, insured <dbl>, uncrowded <dbl>,\r\n#   homeownership <dbl>, automobile <dbl>, commute <dbl>, ...\r\n\r\nCreate the model using regressions and ranger as the engine.\r\n\r\n\r\nranger_pollution <- \r\n  rand_forest(mtry = tune(), \r\n              min_n = tune(), \r\n              trees = 200) %>% \r\n  set_mode(\"regression\") %>% \r\n  set_engine(\"ranger\")\r\n\r\n\r\n\r\nSet up workflow with the recipe and random forest model made above.\r\n\r\n\r\npollution_rfworkflow <- \r\n  workflow() %>% \r\n  add_recipe(pollution_rfrecipe) %>% \r\n  add_model(ranger_pollution) \r\n\r\n\r\n\r\nSet up penalty grid model.\r\n\r\n\r\nrf_penalty_grid <- grid_regular(finalize(mtry(),\r\n                                         pollution_training %>%\r\n                                           select(-log_asthma)),\r\n                                min_n(),\r\n                                levels = 3)\r\n\r\n\r\n\r\nTuned the model and determine the best RMSE.\r\n\r\n\r\nset.seed(456) \r\n\r\npollution_cv <- vfold_cv(pollution_training, v = 5) \r\n\r\npollution_rfTUNE <- \r\n  pollution_rfworkflow %>% \r\n  tune_grid(\r\n    resamples = pollution_cv,\r\n    grid = rf_penalty_grid,\r\n    control = ctrl_grid\r\n  )\r\n\r\nbest_rmse <- \r\n  pollution_rfTUNE %>%\r\n  select_best(metric = \"rmse\")\r\n\r\nbest_rmse\r\n\r\n\r\n# A tibble: 1 x 3\r\n   mtry min_n .config             \r\n  <int> <int> <chr>               \r\n1    32     2 Preprocessor1_Model2\r\n\r\nFitting model to testing data.\r\n\r\n\r\npol_rfFinal <- pollution_rfworkflow %>%\r\n  finalize_workflow(best_rmse) %>%\r\n  fit(data = pollution_training)\r\n\r\n\r\n\r\nFinding the RMSE of the testing data.\r\n\r\n\r\npredictions_rf <- pollution_testing %>% \r\n  select(log_asthma) %>% \r\n  bind_cols(predict(pol_rfFinal, new_data = pollution_testing))\r\n\r\npredictions_rf %>%\r\n  summarize(training_rmse = sqrt(mean((log_asthma - .pred)^2)))\r\n\r\n\r\n  training_rmse\r\n1    0.08511188\r\n\r\n\r\n\r\npredictions_rf %>% \r\n  ggplot(aes(x = log_asthma,\r\n             y = .pred)) +\r\n  geom_point(alpha = .5, \r\n             size = .5) +\r\n  geom_smooth(se = FALSE) +\r\n  geom_abline(slope = 1, \r\n              intercept = 0, \r\n              color = \"darkred\") +\r\n  labs(x = \"Actual log(asthma)\", \r\n       y = \"Predicted log(asthma)\")\r\n\r\n\r\n\r\n\r\nStacking\r\nAfter we had our set of candidate models (9 random forest, 20 lasso, and 10 boost), we started stacking. We followed the process laid out on the stacks webpage.\r\nFirst, we created the stack. Shown by the number of columns, it removed some of the lasso models, likely since they were too similar to other lasso models. The set of candidate models now has 9 random forest, 9 lasso, and 9 boost.\r\n\r\n\r\npollution_stack <- \r\n  stacks() %>% \r\n  add_candidates(boost_tune) %>%\r\n  add_candidates(pollution_lasso_tune) %>% \r\n  add_candidates(pollution_rfTUNE)\r\n\r\n\r\n\r\nWe can look at the predictions from the candidate models in a tibble. Most of the predictions are very close to the actual values, except the first few boost models.\r\n\r\n\r\nas_tibble(pollution_stack)\r\n\r\n\r\n# A tibble: 114 x 28\r\n   log_asthma boost_tune_1_01 boost_tune_1_03 boost_tune_1_04\r\n        <dbl>           <dbl>           <dbl>           <dbl>\r\n 1       3.65             0.5             0.5           0.500\r\n 2       2.06             0.5             0.5           0.500\r\n 3       2.06             0.5             0.5           0.500\r\n 4       2.82             0.5             0.5           0.500\r\n 5       3.05             0.5             0.5           0.500\r\n 6       3.98             0.5             0.5           0.500\r\n 7       1.95             0.5             0.5           0.500\r\n 8       2.29             0.5             0.5           0.500\r\n 9       2.17             0.5             0.5           0.500\r\n10       1.73             0.5             0.5           0.500\r\n# ... with 104 more rows, and 24 more variables:\r\n#   boost_tune_1_05 <dbl>, boost_tune_1_06 <dbl>,\r\n#   boost_tune_1_07 <dbl>, boost_tune_1_08 <dbl>,\r\n#   boost_tune_1_09 <dbl>, boost_tune_1_10 <dbl>,\r\n#   pollution_lasso_tune_1_01 <dbl>, pollution_lasso_tune_1_13 <dbl>,\r\n#   pollution_lasso_tune_1_14 <dbl>, pollution_lasso_tune_1_15 <dbl>,\r\n#   pollution_lasso_tune_1_16 <dbl>, ...\r\n\r\nWe wanted to blend the predictions from each model together to form an even better overall prediction using the blend_predictions() function. Doing this with our models, we see only 4 models have non-zero coefficients, 1 random forest, 2 lasso, and 1 boost:\r\n\r\n\r\nset.seed(456)\r\n\r\npollution_blend <- \r\n  pollution_stack %>% \r\n  blend_predictions()\r\n\r\npollution_blend\r\n\r\n\r\n# A tibble: 4 x 3\r\n  member                    type        weight\r\n  <chr>                     <chr>        <dbl>\r\n1 pollution_rfTUNE_1_2      rand_forest 0.727 \r\n2 boost_tune_1_10           boost_tree  0.282 \r\n3 pollution_lasso_tune_1_18 linear_reg  0.0699\r\n4 pollution_lasso_tune_1_19 linear_reg  0.0127\r\n\r\nHere is the rmse for the various penalty parameters:\r\n\r\n\r\npollution_blend$metrics %>% \r\n  filter(.metric == \"rmse\")\r\n\r\n\r\n# A tibble: 6 x 8\r\n   penalty mixture .metric .estimator  mean     n std_err .config     \r\n     <dbl>   <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>       \r\n1 0.000001       1 rmse    standard   0.104    25 0.00232 Preprocesso~\r\n2 0.00001        1 rmse    standard   0.104    25 0.00232 Preprocesso~\r\n3 0.0001         1 rmse    standard   0.104    25 0.00232 Preprocesso~\r\n4 0.001          1 rmse    standard   0.104    25 0.00234 Preprocesso~\r\n5 0.01           1 rmse    standard   0.105    25 0.00260 Preprocesso~\r\n6 0.1            1 rmse    standard   0.152    25 0.00470 Preprocesso~\r\n\r\nWe can examine some plots to see if we need to adjust the penalty parameter at all. This set of three plots with penalty on the x axis shows that we seem to have captured the smallest RMSE.\r\n\r\n\r\nautoplot(pollution_blend)\r\n\r\n\r\n\r\n\r\nThe blending weights for the top ensemble members are presented in this plot. The random forest has the highest weight, more than two times of the second highest weight boost has. The two lasso models have low weights.\r\n\r\n\r\nautoplot(pollution_blend, type = \"weights\")\r\n\r\n\r\n\r\n\r\nFinally we fit the candidate models with non-zero stacking coefficients to the full training data using fit_members() function. The numeric values of the blending weights for the top ensemble members are also printed out.\r\n\r\n\r\npollution_final_stack <- pollution_blend %>% \r\n  fit_members()\r\n\r\npollution_final_stack\r\n\r\n\r\n# A tibble: 4 x 3\r\n  member                    type        weight\r\n  <chr>                     <chr>        <dbl>\r\n1 pollution_rfTUNE_1_2      rand_forest 0.727 \r\n2 boost_tune_1_10           boost_tree  0.282 \r\n3 pollution_lasso_tune_1_18 linear_reg  0.0699\r\n4 pollution_lasso_tune_1_19 linear_reg  0.0127\r\n\r\nHere is a plot comparing predicted and actual values after fitting it to the testing data. We can see the two lines are almost the same!\r\n\r\n\r\npollution_final_stack %>% \r\n  predict(new_data = pollution_testing) %>% \r\n  bind_cols(pollution_testing) %>% \r\n  ggplot(aes(x = log_asthma, \r\n             y = .pred)) +\r\n  geom_point(alpha = .5, \r\n             size = .5) +\r\n  geom_smooth(se = FALSE) +\r\n  geom_abline(slope = 1, \r\n              intercept = 0, \r\n              color = \"darkred\") +\r\n  labs(x = \"Actual log(asthma)\", \r\n       y = \"Predicted log(asthma)\")\r\n\r\n\r\n\r\n\r\n\r\n\r\ndata_rmse <- pollution_final_stack %>% \r\n  predict(new_data = pollution_testing) %>% \r\n  bind_cols(pollution_testing) \r\n\r\nrmse(data_rmse$log_asthma, data_rmse$.pred)\r\n\r\n\r\n[1] 0.080368\r\n\r\nThe final plot, which shows the blue line of the predicted values nearly match the red line of the ideal values, and the low RMSE show that this model was fairly effective.\r\nModeling Other Variables\r\nWe created models in the same way for three other variables, which you can read about in the links below:\r\nAlzheimer’s disease death rate - here\r\nBreast cancer surgery rate - here\r\nHeart disease death rate - here\r\nOverall, the Alzheimer’s disease death rate model was most effective at predicting the outcome variable and the breast cancer surgery rate model was the least effective. This suggests that many of the factors that worsen Alzheimer’s disease were present in our dataset but that it was missing factors that contribute to breast cancer. This makes sense, as breast cancer has been shown to be hereditary.\r\nLimitations, Troubleshooting, and Potential Repercussions\r\nOne major limitation with this project was the lack of data available. While we initially knew we wanted to focus on the relationship between air pollutants and various health outcomes, we chose to focus solely on California because that was the data that was available. We could only find limited data on air pollutants, so expanded our dataset to include data that we could find on socioeconomic variables. Additionally, many of the air pollutants had missing values, and we found that our dataset only had 13 complete cases that our models were being based on. To deal with this, we filled in all the NA values with the median value for each variable. This likely weakens the models, though they were still fairly strong.\r\nIf we only look at the visualizations displayed in the Shiny app, it is possible to come to conclusions that in reality do not make sense. For example, there seems to be a negative relationship between asthma ER visits and mean annual particulate matter 2.5, despite an extensive body of research and logic that indicate an opposite relationship. That is to say, because we have limited data from a certain area and many other factors play important roles affecting asthma, we should limit conclusions from examining the plots alone. It is also important to keep in mind that these models are not predicting health outcomes for any given individual; they are predicting the per person rate of the health outcome in each county. The models should not be used to determine insurance rates, but they could be used as the basis for policies that, for example, lower air pollutant limits or advocate for more accessible education.\r\nIt is also important to keep in mind that these models are not predicting health outcomes for any given individual; they are predicting the per person rate of the health outcome in each county. The models should not be used to determine insurance rates, but they could be used as the basis for policies that, for example, lower air pollutant limits or advocate for more accessible education.\r\nOutcomes/Future Directions\r\nThe models created in this project were able to predict the chosen outcome variables with a fair amount of accuracy. A next step would be to focus on more interpretable machine learning, specifically creating an interactive ceteris paribus profile to easily visualize the exact impacts of each variable on the predictor.\r\nThe dataset we created contains numerous other health outcomes, each of which could be the subject of its own model with relatively little additional work. We chose to model the outcomes that we did because of previous research tying them to environmental factors, but it would be interesting to look for connections for the other variables as well.\r\nAdditionally, it would be useful to add more predictors to the dataset, especially those focused on the race and age distributions of each county. Those are currently missing from the dataset we built but are known risk factors for many health outcomes, so adding them may help to reveal any potentially confounding variables.\r\n\r\n\r\n\r\n",
    "preview": "capstones/Advanced Data Science/Advanced-Data-Science_files/figure-html5/unnamed-chunk-5-1.png",
    "last_modified": "2021-12-16T10:32:12-06:00",
    "input_file": {}
  },
  {
    "path": "capstones/Bayesian Statistics/",
    "title": "Risk and Protective Factors for Serious Mental Illness among Patients Receiving Public Mental Health Services",
    "description": "Bayesian Statistics",
    "author": [
      {
        "name": "Yunyang Zhong",
        "url": {}
      }
    ],
    "date": "2021-12-14",
    "categories": [],
    "contents": "\r\nSlides\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(kableExtra)\r\nlibrary(tidybayes)\r\nlibrary(rstan)\r\nlibrary(rstanarm)\r\nlibrary(bayesplot)\r\nlibrary(bayesrules)\r\nlibrary(broom.mixed)\r\nlibrary(janitor)\r\nlibrary(e1071)\r\nlibrary(klaR)\r\nlibrary(groupdata2)\r\nlibrary(patchwork)\r\nsurvey <- read_csv(\"Survey_PCS_2017.csv\")\r\n\r\n\r\n\r\nIntoduction\r\nThere are well documented disparities in mental health outcomes between transgender people and their cisgender (ie not transgender) peers (Goldenberg et al. 2019; McDowell, Hughto, & Reisner, 2019; Flores et al., 2018; Bailey, Ellis, & McNeil, 2014; Haas, Rodgers, & Herman, 2014). Bailey, Ellis, & McNeil (2014) found 84% prevalence of suicidal ideation and 48% prevalence of suicide attempt history among trans people. This suicide attempt rate is more than ten times the national average of 4.6% (Haas, Rodgers, & Herman, 2014). The disparities are especially large for transgender people of color (TPOC) (Goldenberg et al. 2019; Flores et al., 2018; Haas, Rodgers, & Herman, 2014). Hass, Rodgers, & Herman (2014) found that white trans people surveyed had the lowest suicide attempt rate of any racial group at 38%, while the suicide attempt rate for TPOC ranged from 39% (Asian American) to 44% (Hispanic/Latino) to 45% (Black) to 54% (multiracial) to 56% (Native American). This may be related to the fact that TPOC are at much higher risk of violence (including harassment, physical, sexual, and intimate partner) than white trans people (Flores et al., 2018).\r\nBecause of this we thought it would be important to look for protective factors against poor mental health outcomes, in particular for trans people, and especially TPOC. McDowell, Hughto, & Reisner (2019) asked a similar question and found that lack of employment, lower income and education level, daily discrimination, and violence were all significant risk factors for mental illness among trans people. These could potentially point to places for short term intervention in a transphobic world resistant to (much needed) radical change.\r\nOur Data\r\nHowever, we were limited by the small number of publicly available data sets that collect information about transgender identity. We ended up using data from the 2017 Patient Characteristics Study (PCS), conducted by the New York State Office of Mental Health to better understand and reform the public mental health system. The PCS collects information about every client receiving public mental health services in the state of New York for a one week period, every 2 years. In 2017 there were 175,926 patients recorded, 1,844 of which identified as themselves as transgender. You can learn more about the study here: https://omh.ny.gov/omhweb/pcs/submissions/. We downloaded the data from https://catalog.data.gov/dataset/patient-characteristics-survey-pcs-2017.\r\nOne major limitation of this data set is because everyone included in it is receiving public mental health services, it is not representative of the general population. Another limitation is lack of diversity of mental health outcome measures, including only “mental illness”, “serious mental illness”, “drug substance disorder”, and “alcohol related disorder” but excluding outcomes like suicide attempts, self injury, or specific diagnoses. Our initial research question asked what factors are associated with better mental health outcomes for trans people, i.e. what mediates or moderates the relationship between trans identity and poor mental health? However, unlike the trends found in the general population, in this population being transgender was not significantly related to any measured mental health outcome. Thus, we shifted our focus to ask what broader factors predict serious mental illness, such as race, employment, age, sexual orientation, and education.\r\n\r\n\r\ndata.frame(variable = c(\"Transgender\", \"Mental Illness\", \"Race\", \"Hispanic Ethnicity\", \"Sexual Orientation\", \"Age Group\", \"Serious Mental Illness\", \"Alcohol Related Disorder\", \"Drug Substance Disorder\", \"Education Status\", \"Number Of Hours Worked Each Week\"), meaning = c(\"YES or NO\", \"YES or NO\", \"WHITE ONLY, BLACK ONLY, MULTI-RACIAL, or OTHER\", \"YES or NO\", \"BISEXUAL, LESBIAN/GAY, STRAIGHT/HETEROSEXUAL, or OTHER\", \"ADULT or CHILD\", \"YES or NO\", \"YES or NO\", \"YES or NO\", \"COLLEGE OR GRADUATE DEGREE, MIDDLE SCHOOL TO HIGH SCHOOL, NO FORMAL EDUCATION, OTHER, PRE-K TO FIFTH GRADE, SOME COLLEGE\", \"01-14 HOURS, 15-34 HOURS, 35 HOURS OR MORE, or NOT APPLICABLE\")) %>% \r\n  kbl() %>% \r\n  kable_styling(position = \"center\")\r\n\r\n\r\n\r\nvariable\r\n\r\n\r\nmeaning\r\n\r\n\r\nTransgender\r\n\r\n\r\nYES or NO\r\n\r\n\r\nMental Illness\r\n\r\n\r\nYES or NO\r\n\r\n\r\nRace\r\n\r\n\r\nWHITE ONLY, BLACK ONLY, MULTI-RACIAL, or OTHER\r\n\r\n\r\nHispanic Ethnicity\r\n\r\n\r\nYES or NO\r\n\r\n\r\nSexual Orientation\r\n\r\n\r\nBISEXUAL, LESBIAN/GAY, STRAIGHT/HETEROSEXUAL, or OTHER\r\n\r\n\r\nAge Group\r\n\r\n\r\nADULT or CHILD\r\n\r\n\r\nSerious Mental Illness\r\n\r\n\r\nYES or NO\r\n\r\n\r\nAlcohol Related Disorder\r\n\r\n\r\nYES or NO\r\n\r\n\r\nDrug Substance Disorder\r\n\r\n\r\nYES or NO\r\n\r\n\r\nEducation Status\r\n\r\n\r\nCOLLEGE OR GRADUATE DEGREE, MIDDLE SCHOOL TO HIGH SCHOOL, NO FORMAL EDUCATION, OTHER, PRE-K TO FIFTH GRADE, SOME COLLEGE\r\n\r\n\r\nNumber Of Hours Worked Each Week\r\n\r\n\r\n01-14 HOURS, 15-34 HOURS, 35 HOURS OR MORE, or NOT APPLICABLE\r\n\r\n\r\nData Cleaning\r\n\r\n\r\n# cleaning the data!\r\nsurvey_cleaned <- survey %>% \r\n  filter(Transgender == \"NO, NOT TRANSGENDER\" | Transgender == \"YES, TRANSGENDER\") %>%\r\n  filter(Race == \"WHITE ONLY\" | Race == \"BLACK ONLY\" | Race == \"MULTI-RACIAL\" | Race == \"OTHER\") %>% \r\n  filter(`Alcohol Related Disorder` == \"YES\" | `Alcohol Related Disorder` == \"NO\") %>% \r\n  filter(`Drug Substance Disorder` == \"YES\" | `Drug Substance Disorder` == \"NO\") %>% \r\n  filter(`Education Status` != \"UNKNOWN\") %>% \r\n  filter(`Hispanic Ethnicity` != \"UNKNOWN\") %>% \r\n  filter(`Number Of Hours Worked Each Week` != \"UNKNOWN EMPLOYMENT HOURS\") %>% \r\n  filter(`Mental Illness` != \"UNKNOWN\") %>% \r\n  filter(`Age Group` != \"UNKNOWN\") %>%\r\n  filter(`Serious Mental Illness` != \"UNKNOWN\") %>% \r\n  filter(`Sexual Orientation` != \"CLIENT DID NOT ANSWER\") %>% \r\n  filter(`Sexual Orientation` != \"UNKNOWN\") %>% \r\n  mutate(`Number Of Hours Worked Each Week` = fct_recode(`Number Of Hours Worked Each Week`, \"1-14\" = \"01-14 HOURS\",\r\n                                                         \"15-34\" = \"15-34 HOURS\", \"35+\" = \"35 HOURS OR MORE\")) %>% \r\n  mutate(Transgender = fct_recode(Transgender, \"NOT TRANSGENDER\" = \"NO, NOT TRANSGENDER\",\r\n                                  \"TRANSGENDER\" = \"YES, TRANSGENDER\")) %>% \r\n  mutate(`Hispanic Ethnicity` = fct_recode(`Hispanic Ethnicity`, \"NOT HISPANIC/LATINO\" = \"NO, NOT HISPANIC/LATINO\", \"HISPANIC/LATINO\" = \"YES, HISPANIC/LATINO\"))\r\n\r\n\r\n\r\nWe removed unknown/not answered values for each variable.\r\nData Viz\r\nIn our to get a sense of our data we first look at the two most basic demographic features we decided to focus on: transgender identity and race.\r\n\r\n\r\np3 <- survey_cleaned %>%\r\n  ggplot()+\r\n  geom_bar(aes(x = Transgender, fill = Transgender))+\r\n  labs(title = \"Figure 1: Transgender Identity\")+\r\n  theme(legend.position = \"bottom\", legend.title = element_blank())\r\n\r\np4 <- survey_cleaned %>%\r\n  ggplot()+\r\n  geom_bar(aes(x = Race, fill = `Hispanic Ethnicity`))+\r\n  labs(title = \"Figure 2: Race & Ethnicity\")+\r\n  theme(axis.text.x = element_text(angle=20), legend.position = \"bottom\", legend.title = element_blank())\r\n\r\np5 <- survey_cleaned %>% \r\n  ggplot(aes(x = Transgender, fill = Race)) +\r\n  labs(title = \"Figure 3: Race & Transgender Identity\")+\r\n  geom_bar(position = \"fill\")+\r\n  theme(legend.title = element_blank())\r\n\r\np3 | p4\r\n\r\n\r\n\r\np5\r\n\r\n\r\n\r\n\r\nAfter cleaning we still see that the majority of patients are not transgender (figure 1).\r\nThis survey collected information on race (“Black only”, “white only”, “multiracial”, or “other”) and ethnicity (“Hispanic/Latino” or not) separately. We can see that the sample has about twice as many “white only” respondents as “Black only” respondents. We also see that there are respondents identified as “Hispanic/Latino” in all four racial categories collected, with the highest number in the category “other” (figure 2).\r\nAdditionally, we can see that a slightly higher percentage of transgender patients were “white only”, compared to patients who are not transgender (figure 3). Just over 50% of both groups were “white only”, and around 25% were “Black only” (figure 3).\r\nNext, we looked for any easily visible differences in mental health outcomes by transgender identity in this population.\r\n\r\n\r\np6 <- survey_cleaned %>% \r\n  ggplot(aes(x = Transgender, fill = `Alcohol Related Disorder`)) +\r\n  geom_bar(position = \"fill\")+\r\n  labs(title = \"Figure 6: Alcohol Related Disorder\")+\r\n  theme(legend.position = \"bottom\")\r\n\r\np7 <- survey_cleaned %>% \r\n  ggplot(aes(x = Transgender, fill = `Drug Substance Disorder`)) +\r\n  geom_bar(position = \"fill\")+\r\n  labs(title = \"Figure 7: Drug Substance Disorder\")+\r\n  theme(legend.position = \"bottom\")\r\n\r\np8 <- survey_cleaned %>% \r\n  ggplot(aes(x = `Transgender`, fill = as.factor(`Serious Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Figure 5: Serious Mental Illness\")+\r\n  theme(legend.position = \"bottom\") +\r\n  labs(fill = \"Serious Mental Illness\")\r\n\r\np9 <- survey_cleaned %>% \r\n  ggplot(aes(x = `Transgender`, fill = as.factor(`Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Figure 4: Mental Illness\")+\r\n  theme(legend.position = \"bottom\") +\r\n  labs(fill = \"Mental Illness\")\r\n\r\np9 | p8\r\n\r\n\r\n\r\np6 | p7\r\n\r\n\r\n\r\n\r\nWe can see that there is almost no visible difference between transgender and cisgender (not transgender) patients for any of the four mental health outcomes (figures 4, 5, 6, & 7). We also see that almost our entire sample has mental illness (figure 4), over 90% have serious mental illness (figure 5), and around an 8th have alcohol and/or substance disorders (figures 6 & 7).\r\nBecause none of these outcome variables seemed more related to transgender identity than another, and because there were almost no patients without mental illness, we chose serious mental illness as our outcome variable.\r\nNext, we visualized how the other demographic variables we were interested in related to serious mental illness.\r\n\r\n\r\np10 <- survey_cleaned %>% \r\n  ggplot(aes(x = `Race`, fill = as.factor(`Serious Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Figure 8: Serious Mental Illness by Race\")+\r\n  theme(legend.position = \"bottom\") +\r\n  labs(fill = \"Serious Mental Illness\")\r\n\r\np11 <- survey_cleaned %>% \r\n  ggplot(aes(x = `Age Group`, fill = as.factor(`Serious Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Figure 9: Serious Mental Illness by Age\")+\r\n  theme(legend.position = \"bottom\") +\r\n  labs(fill = \"Serious Mental Illness\")\r\n\r\np12 <- survey_cleaned %>% \r\n  ggplot(aes(x = `Number Of Hours Worked Each Week`, fill = as.factor(`Serious Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Figure 10: Serious Mental Illness by Hours Worked\")+\r\n  theme(legend.position = \"bottom\") +\r\n  labs(fill = \"Serious Mental Illness\")\r\n\r\np13 <- survey_cleaned %>% \r\n  ggplot(aes(x = fct_relevel(`Education Status`, c(\"NO FORMAL EDUCATION\", \"PRE-K TO FIFTH GRADE\", \"MIDDLE SCHOOL TO HIGH SCHOOL\", \"SOME COLLEGE\", \"COLLEGE OR GRADUATE DEGREE\", \"OTHER\")), fill = as.factor(`Serious Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Figure 11: Serious Mental Illness by Education\")+\r\n  theme(axis.text.x = element_text(angle=20), legend.position = \"bottom\") +\r\n  labs(fill = \"Serious Mental Illness\", x = \"Education status\")\r\n\r\np10 | p11\r\n\r\n\r\n\r\np12 | p13\r\n\r\n\r\n\r\n\r\nWe see no clear difference in serious mental illness by race (figure 8). Child patients, however, appear to be less likely than adult patients to have serious mental illness (figure 9). Additionally, the more hours a patient works each week, it appears slightly less likely that they have serious mental illness (figure 10). Perhaps related to age, less education (this does not control for age) appears associated with being less likely to have serious mental illness (figure 11).\r\nWe made many more plots that are not included here, playing with different arrangements of these variables. The only one that was interesting enough to include looked at both transgender identity and age as predictors of serious mental illness.\r\n\r\n\r\np14 <- survey_cleaned %>%\r\n  ggplot(aes(x = `Transgender`, fill = as.factor(`Serious Mental Illness`))) +\r\n  geom_bar(position = \"fill\") +\r\n  facet_wrap(vars(`Age Group`))+\r\n  labs(title = \"Figure 12: Serious Mental Illness by Age & Trans Identity\")+\r\n  theme(legend.position = \"bottom\") +\r\n  labs(fill = \"Serious Mental Illness\")\r\n\r\np14\r\n\r\n\r\n\r\n\r\nHere we see in figure 12 that while there is no difference in serious mental illness between trans and cis patients among adults, child patients who are transgender appear considerably more likely than their cis peers to have serious mental illness.\r\nOverall this data visualization affirmed that the population in this survey is unique – it does not show the dramatic trends of worse mental health outcomes for trans people found in the larger population. Our data visualization also indicates that age, hours worked, and education may be our most important predictor variables for serious mental illness.\r\nModel Building\r\n\r\n\r\nset.seed(494)\r\nsmall_survey <- survey_cleaned %>%\r\n  group_by(Transgender) %>%\r\n  sample_frac(0.1) %>%\r\n  ungroup() %>% \r\n  rename(serious = 'Serious Mental Illness') %>%\r\n  mutate_if(is.character,as.factor) %>%\r\n  dplyr::select(serious, Transgender, Race, `Sexual Orientation`, `Age Group`, `Education Status`, `Alcohol Related Disorder`, `Drug Substance Disorder`, `Number Of Hours Worked Each Week`) %>%\r\n  mutate(serious = as.factor(serious)) %>% \r\n  mutate(`Number Of Hours Worked Each Week` = fct_recode(`Number Of Hours Worked Each Week`, \"01-14 HOURS\" = \"1-14\", \"15-34 HOURS\" = \"15-34\", \"35 HOURS OR MORE\" = \"35+\")) %>% \r\n  mutate(Transgender = fct_recode(Transgender, \"NO, NOT TRANSGENDER\" = \"NOT TRANSGENDER\",\r\n                                  \"YES, TRANSGENDER\" = \"TRANSGENDER\"))\r\n\r\nsmall_survey <- downsample(small_survey, \"serious\")\r\n\r\n\r\n\r\nBecause our data is very unbalanced and the majority of observations have serious mental illness, we decided to downsample so that there are equal amounts of patients with and without serious mental illness in our modeling data. In this way we can prevent models from classifying everything as having serious mental illness.\r\nThrough model model building we hoped to examine how well various demographic factors can predict serious mental illness. Because our response variable (serious mental illness) is binary, we had two options: Naive Bayes and Logistic Regression. For each, we began by examining transgender identity and race separately. Our preference is logistic regression because we would like to know which predictors are more important and how they influence the outcome. Although Naive Bayes does not satisfy this aspect, we still wanted to build and see if it can produce better accuracy. Later we decided that Naive Bayes was not useful to our project, and instead created more Logistic Regression models with more variables.\r\nNaive Bayes\r\n\\[\r\nf(\\text{Serious Mental Illness}|\\text{Transgender})\\sim f(\\text{Serious Mental Illness})L(\\text{Serious Mental Illness}|\\text{Transgender})\r\n\\]\r\nf(Serious Mental Illness) can be calculated using numbers of patients with and without serious mental illness in the observations. The likelihood can be computed in the similar way.\r\n\r\n\r\n# naive Bayes model trans predicts serious\r\nnaive_trans_serious <- naiveBayes(\r\n  serious ~ Transgender,\r\n  data = small_survey)\r\n\r\n\r\n\r\n\r\n\r\n# look at trans predicts serious naive Bayes model\r\nnaive_classification_summary_cv(model = naive_trans_serious, data = small_survey, y=\"serious\", k=10)\r\n\r\n\r\n$folds\r\n   fold        NO        YES overall_accuracy\r\n1     1 0.0000000 1.00000000        0.4842767\r\n2     2 1.0000000 0.01149425        0.4591195\r\n3     3 1.0000000 0.03703704        0.5094340\r\n4     4 0.9729730 0.00000000        0.4556962\r\n5     5 1.0000000 0.00000000        0.5031447\r\n6     6 0.0000000 1.00000000        0.4591195\r\n7     7 1.0000000 0.01282051        0.5126582\r\n8     8 0.0000000 1.00000000        0.4779874\r\n9     9 0.0000000 1.00000000        0.4528302\r\n10   10 0.9861111 0.00000000        0.4465409\r\n\r\n$cv\r\n serious           NO          YES\r\n      NO 57.05% (453) 42.95% (341)\r\n     YES 61.84% (491) 38.16% (303)\r\n\r\nSensitivity refers to the proportion of those who have the condition that received a positive result on a test. In this case it means what proportion of patients who have serious mental illness are categorized as having serious mental illness by our model. Specificity refers to the proportion of those who do not have the condition that received a negative result on a test. In this case it means what proportion of patients who do no have serious mental illness are categorized as not having serious mental illness by our model.\r\nModel #1: After down sampling, this Naive Bayes model, which uses only Transgender as a predictor, no longer classifies everyone as seriously mentally ill. However, looking at the classification summary we can see that this model does a really poor job classifying patients, with a sensitivity of 38.16% – worse than chance – and a specificity of 57.05% – barely above chance. From this we might conclude Transgender alone is a poor predictor of serious mental illness among patients using public mental health services and this Naive Bayes model is not a preferred one.\r\n\\[\r\nf(\\text{Serious Mental Illness}|\\text{Race})\\sim f(\\text{Serious Mental Illness})L(\\text{Serious Mental Illness}|\\text{Race})\r\n\\]\r\nf(Serious Mental Illness) can be calculated using numbers of patients with and without serious mental illness in the observations. The likelihood can be computed in the similar way.\r\n\r\n\r\n# naive Bayes model with Race predicts serious\r\nnaive_race_serious <- naiveBayes(\r\n  serious ~ Race,\r\n  data = small_survey)\r\n\r\n\r\n\r\n\r\n\r\n# look at serious predicts Race naive Bayes model\r\nnaive_classification_summary_cv(model = naive_race_serious, data = small_survey, y=\"serious\", k=10)\r\n\r\n\r\n$folds\r\n   fold        NO       YES overall_accuracy\r\n1     1 0.8395062 0.2435897        0.5471698\r\n2     2 0.8148148 0.2179487        0.5220126\r\n3     3 0.8493151 0.2558140        0.5283019\r\n4     4 0.7236842 0.2682927        0.4873418\r\n5     5 0.7972973 0.2705882        0.5157233\r\n6     6 0.7341772 0.3500000        0.5408805\r\n7     7 0.8292683 0.1973684        0.5253165\r\n8     8 0.7750000 0.3291139        0.5534591\r\n9     9 0.8539326 0.3142857        0.6163522\r\n10   10 0.8227848 0.3750000        0.5974843\r\n\r\n$cv\r\n serious           NO          YES\r\n      NO 80.48% (639) 19.52% (155)\r\n     YES 71.79% (570) 28.21% (224)\r\n\r\nModel #2: This model, using only race as a predictor of serious mental illness, has a tendency to classify patients as not having serious mental illness, with a specificity of 80.48% and sensitivity of 28.21%. This also indicates that this model does not do a great job at predicting serious mental illness, so race also may not be a good predictor.\r\nTake-away: Since with Naive Bayes we cannot analyze the impact of individual predictors, we decided for the rest of our project to use logistic models.\r\nLogistic Regression\r\n\\[\r\n\\begin{aligned}\r\n&\\text{Serious Mental Illness}|\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4, \\beta_5, \\beta_6, \\beta_7, \\sigma\\overset{\\text{ind}}{\\sim}\\text{Bern}(\\pi_i)\r\n\\\\\r\n&\\text{where }\\text{log}(\\frac{\\pi_i}{1-\\pi_i})=\\beta_0 + \\beta_1\\text{Transgender} + \\beta_2\\text{RaceMULTI} + \\beta_3\\text{RaceOTHER}\r\n\\\\\r\n& + \\beta_4\\text{RaceWHITE} + \\beta_5\\text{SexualOrientationLESBIAN|GAY}\r\n\\\\\r\n& + \\beta_6\\text{SexualOrientationOTHER} + \\beta_7\\text{SexualOrientationSTRAIGHT|HETEROSEXUAL}\r\n\\\\\r\n&\\beta_0\\sim\\text{N}(0, s_0^2)\r\n\\\\\r\n&\\beta_1\\sim\\text{N}(0, s_1^2)\r\n\\\\\r\n&\\beta_2\\sim\\text{N}(0, s_2^2)\r\n\\\\\r\n&\\beta_3\\sim\\text{N}(0, s_3^2)\r\n\\\\\r\n&\\beta_4\\sim\\text{N}(0, s_4^2)\r\n\\\\\r\n&\\beta_5\\sim\\text{N}(0, s_5^2)\r\n\\\\\r\n&\\beta_6\\sim\\text{N}(0, s_6^2)\r\n\\\\\r\n&\\beta_7\\sim\\text{N}(0, s_7^2)\r\n\\end{aligned}\r\n\\]\r\nWe chose a weakly informative prior with coefficients centered around 0 with wide variances. Race and Sexual Orientation each has 4 categories.\r\n\r\n\r\nlogistic3 <- stan_glm(\r\n  serious ~ Transgender + Race + `Sexual Orientation`,\r\n  data = small_survey,\r\n  family = binomial,\r\n  chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\r\n\r\n# Save an object to a file\r\nsaveRDS(logistic3, file = \"logistic3.rds\")\r\n\r\n\r\n\r\n\r\n\r\nlogistic3 <- readRDS(file = \"logistic3.rds\")\r\n\r\nclassification_summary(model = logistic3, data = small_survey)\r\n\r\n\r\n$confusion_matrix\r\n   y   0   1\r\n  NO 624 170\r\n YES 546 248\r\n\r\n$accuracy_rates\r\n                          \r\nsensitivity      0.3123426\r\nspecificity      0.7858942\r\noverall_accuracy 0.5491184\r\n\r\nModel #3: This logistic model uses transgender, race, and sexual orientation to predict serious mental illness. The sensitivity is much lower than the specificity – meaning this model has a tendency to categorize patients as not seriously mentally ill when they are, but when patients are categorized as mentally ill they (most) likely are. Overall the accuracy of the model is very low at 0.549 – barely above chance because our response variable is binary.\r\n\\[\r\n\\begin{aligned}\r\n&\\text{Serious Mental Illness}|\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\cdots, \\sigma\\overset{\\text{ind}}{\\sim}\\text{Bern}(\\pi_i)\r\n\\\\\r\n&\\text{where }\\text{log}(\\frac{\\pi_i}{1-\\pi_i})=\\beta_0 + \\beta_1{X_1} + \\beta_2{X_2} + \\beta_3{X_3} + \\cdots\r\n\\\\\r\n&X_i =  \\text{Transgender, Race, Sexual Orientation, Age Group, Education Status,}\r\n\\\\\r\n&\\text{Alcohol Related Disorder, Drug Substance Disorder, Number of Hours Worked Each Week}\r\n\\\\\r\n&\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\cdots\\sim\\text{N}(0, s_i^2)\r\n\\end{aligned}\r\n\\]\r\nWe chose a weakly informative prior with coefficients centered around 0 with wide variances.\r\n\r\n\r\nlogistic4 <- stan_glm(\r\n  serious ~ Transgender + Race + `Sexual Orientation` + `Age Group` + `Education Status` + `Alcohol Related Disorder` + `Drug Substance Disorder` + `Number Of Hours Worked Each Week`,\r\n  data = small_survey,\r\n  family = binomial,\r\n  chains = 4, iter = 5000*2, seed = 84735, refresh = 0)\r\n\r\n# Save an object to a file\r\nsaveRDS(logistic4, file = \"logistic4.rds\")\r\n\r\n\r\n\r\n\r\n\r\n# Restore the object\r\nlogistic4 <- readRDS(file = \"logistic4.rds\")\r\n\r\n\r\n\r\nMCMC Simulation Diagnostics\r\n\r\n\r\n# Trace plots\r\nmcmc_trace(logistic4)\r\n\r\n\r\n\r\n# Overlaid density plots\r\nmcmc_dens_overlay(logistic4)\r\n\r\n\r\n\r\n\r\nBecause we utilized MCMC simulation to build our model, the first thing we need to do is to check whether the simulation was well performed. The trace plots are random and overlaid density plots produce similar posterior approximations, so the simulation is stable and trustworthy.\r\nPosterior Predictive Check\r\n\r\n\r\n# Construct a posterior predictive check\r\npp_check(logistic4)\r\n\r\n\r\n\r\n\r\nAlthough we now have a better understanding of the simulation outcome, we are still not sure how the model is doing. So, the next question is, how wrong is the model? pp_check shows that the prediction is close to actual data and the model is not wrong.\r\nModel Evaluation Metrics\r\n\r\n\r\nclassification_summary_cv(model = logistic4, data = small_survey, cutoff = 0.6, k = 5)$cv\r\n\r\n\r\n  sensitivity specificity overall_accuracy\r\n1   0.5333068   0.7050371        0.6183799\r\n\r\nSince logistic regression models produce a probability, how well they classify patients in our data set as seriously mentally ill or not depends on the cut off we choose. For example, in the classification summaries of the models above, if the model said there was >0.6 probability of serious mental illness, the patient was classified as seriously mentally ill. When looking at model 4 we varied the cutoff between 0.6, 0.65, and 0.7, and used both regular and cross validated classification summaries.\r\nAcross these 6 summaries overall accuracy ranged from 0.549 to 0.639, with lower accuracy the higher the cutoff, and with cv versus regular classification. Intuitively, sensitivity decreased and specificity increased as the cutoff was raised, ranging from 0.184 to 0.553 and 0.710 to 0.933 respectively. This model also had a tendency to classify patients as not having serious mental illness. We decided to use 0.6 as our cutoff in order to keep sensitivity, specificity, and overall accuracy all relatively high.\r\nCoefficient Interpretation\r\n\r\n\r\ntidy(logistic4, effects = c(\"fixed\", \"aux\"), conf.int = TRUE, conf.level = 0.80)\r\n\r\n\r\n# A tibble: 20 x 5\r\n   term                          estimate std.error conf.low conf.high\r\n   <chr>                            <dbl>     <dbl>    <dbl>     <dbl>\r\n 1 (Intercept)                     1.65      0.483    1.04      2.27  \r\n 2 TransgenderYES, TRANSGENDER     0.281     0.608   -0.477     1.08  \r\n 3 RaceMULTI-RACIAL               -0.368     0.324   -0.782     0.0405\r\n 4 RaceOTHER                      -0.275     0.173   -0.498    -0.0496\r\n 5 RaceWHITE ONLY                 -0.380     0.136   -0.555    -0.205 \r\n 6 `Sexual Orientation`LESBIAN ~  -0.284     0.422   -0.822     0.267 \r\n 7 `Sexual Orientation`OTHER       0.205     0.607   -0.592     0.979 \r\n 8 `Sexual Orientation`STRAIGHT~  -0.204     0.339   -0.637     0.235 \r\n 9 `Age Group`CHILD               -1.35      0.156   -1.55     -1.14  \r\n10 `Education Status`MIDDLE SCH~  -0.491     0.173   -0.715    -0.272 \r\n11 `Education Status`NO FORMAL ~  -1.99      1.32    -4.01     -0.481 \r\n12 `Education Status`OTHER         0.539     0.543   -0.137     1.28  \r\n13 `Education Status`PRE-K TO F~  -1.07      0.277   -1.43     -0.726 \r\n14 `Education Status`SOME COLLE~  -0.406     0.206   -0.670    -0.137 \r\n15 `Alcohol Related Disorder`YES   0.366     0.234    0.0649    0.668 \r\n16 `Drug Substance Disorder`YES    0.0856    0.183   -0.150     0.319 \r\n17 `Number Of Hours Worked Each~  -0.796     0.361   -1.26     -0.330 \r\n18 `Number Of Hours Worked Each~  -1.72      0.358   -2.18     -1.27  \r\n19 `Number Of Hours Worked Each~  -0.215     0.314   -0.621     0.191 \r\n20 mean_PPD                        0.5       0.0161   0.479     0.521 \r\n\r\nModel #4: This model uses every predictor variable we considered to predict serious mental illness: Transgender, Race, Sexual Orientation, Age Group, Education Status, Alcohol Related Disorder, Drug Substance Disorder, and Hours Worked. While some of these may be predictors of interest, others are there as controls. Thus, while looking at each of these predictors it’s important to remember the rest of them are controlled for.\r\nTransgender and sexual orientation: Both the transgender and all three sexual orientation coefficients had both positive and negative values within their 80% credible intervals, and so do not have a clear relationship with serious mental illness among patients using public mental health services. This may be because of the uniqueness of the population in this study, because increased risk of serious mental illness is well documented for queer and trans people (Goldenberg et al. 2019; McDowell, Hughto, & Reisner, 2019; Flores et al., 2018; Bailey, Ellis, & McNeil, 2014; Haas, Rodgers, & Herman, 2014). The median estimate for transgender is exp(0.28)=1.32, meaning being transgender leads to a 1.32 times odds to have serious mental illness, holding other predictors constant. Similarly, the median estimate for Sexual OrientationLESBIAN OR GAY is -0.28, Sexual OrientationOTHER 0.21, and Sexual OrientationSTRAIGHT OR HETEROSEXUAL -0.20. That is to say, LESBIAN OR GAY and STRAIGHT OR HETEROSEXUAL have 0.75 and 0.82 times the odds to have serious mental illness comparing to BISEXUAL while those who choose OTHER for Sexual Orientation have 1.23 times the odds comparing to BISEXUAL, controlling all other variables.\r\nRace: For this variable the model default was “Black only”. Both the “other” and “white only” racial category coefficients were negative across their 80% credible intervals, ranging from -0.498 to -0.050 and -0.555 to -0.205. The median estimates are -0.28 and -0.38 for the “other” and “white only” racial categories, meaning it is possible that patients who identified their race as “other” or “white only” have exp(-0.28)=0.75 and exp(-0.38)=0.68 times the odds to have serious mental illness compared to patients who identified their race as “Black only” (the model default), holding other predictors constant. Note: the “other” racial category we saw above was primarily Hispanic/Latino, but may also include Asian and Native Americans, or other racial categories that didn’t fit into either “Black only”, “white only”, or “multiracial”. The “multiracial” category had both positive and negative coefficient estimates in their 80% credible intervals, meaning there wasn’t a clear difference in prevalence of serious mental illness between “Black only” and “multiracial” patients. This may be indicative of a larger trend of anti-Blackness creating worse health outcomes for Black patients (especially considering many of the “multiracial” patients may be Black along with their other racial identities). There are documented disparities between white and Black people in healthcare, including greater difficulty accessing insurance and care, and poorer quality of care (Brenick, Romano, Kegler, & Eaton, 2017). These disparities are exacerbated for queer Black people (Brenick, Romano, Kegler, & Eaton, 2017). While the evidence from the unique population in this survey alone is not nearly enough to conclude this a sign of anti-Blackness, these results are in line with larger trends.\r\nAge group: The child coefficient estimate in the 80% credible interval ranges from -1.546 to -1.144, so it would appear that (when controlling for the other predictors in this model) a child patient using public mental health services is less likely (exp(-1.35)=0.26 times) than an adult patient to have serious mental illness – this makes sense given that many serious mental illnesses first develop in young adulthood.\r\nEducation: First, it is important to remember this model controls for age. Counter-intuitively, the less education a patient has, it would seem according to this model, the less likely they are to have serious mental illness. The model default was the highest level of education on the survey: a college degree. The 80% credible interval of the coefficient estimate was -4.008 to -0.481 for no formal education, -1.434 to -0.726 for pre-K to 5th grade, -0.715 to -0.272 for middle to high school, and -0.670 to -0.137 for some college. That is to say, people in any of these groups are less likely to have serious mental illness comparing to people having a college degree, controlling all other variables. This result is the opposite of what McDowell, Hughto, & Reisner (2019) found, that education is a protective factor. This may be related to the uniqueness of this survey’s population. Since all respondents are receiving public mental health services, not having serious mental illness then must be associated with some other reason for accessing these services. For example, if a respondent doesn’t have serious mental illness they may be more likely to have traumatic brain injury or intellectual disability, which may be associated with receiving less education, especially because the onset of these conditions may be earlier than for serious mental illness.\r\nAlcohol & substance disorders: Having an alcohol related disorder seemed to be associated with a higher likelihood (exp(0.37)=1.45 times) of serious mental illness, controlling all other variables, with the coefficient estimate’s 80% credible interval ranging from 0.065 to 0.668. Substance related disorders, on the other hand, had a coefficient estimate that was both positive and negative in the 80% credible interval.\r\nHours Worked: The model default was working less than 15 hours per week. Working 15-34 hours per week and 35+ hours per week had coefficients ranging from -1.263 to -0.330 and -2.177 to -1.269 respectively, meaning that working more hours may be associated with lower rates (exp(-0.80)=0.45 times / exp(-1.72)=0.18 times) of serious mental illness, holding other predictors constant. This is intuitive because serious mental illness could make it difficult for a person to work. Oddly, the number of hours worked not applicable (likely meaning the patient is unemployed) coefficient had both positive and negative values in the 80% credible interval, and so is not clearly different from the default.\r\nTake-away: (when controlling for the other predictors in this model) Patients who identified their race as “other” or “white only”, their age as “child”, have less than a college degree, and work more hours are significantly less likely to have serious mental illness. Patients having an alcohol related disorder are significantly more likely to have serious mental illness.\r\nConclusion and Next Steps\r\nOverall we found that being a child, identifying race as “white only” or “other”, having less than a college degree, and/or working more hours per week were associated with less chance of having serious mental illness (when controlling for the other predictors in this model). While age and hours worked and education level (as discussed above) may be inherently related to serious mental illness and/or this population, the relevance of race may point to systemic man-made factors that could be changed to promote better mental health for everyone.\r\nDirections for further analysis of this data set might include using predictors we didn’t (there were 67 variables total!), or exploring other response variables. For example, some patients in the data set were in inpatient, some in outpatient, and others in residential treatments. This could be used as a proxy for mental health severity rather than solely looking at diagnosis as we did.\r\nAnother way to use this data set could be comparing it to the demographic data of New York state as a whole, and seeing which groups are over or under represented in the public mental health system.\r\nIn order to find protective factors against worse mental health outcomes, it would be ideal to have data that included healthy people as well as those needing treatment. For this reason, it is important for anyone collecting data on mental health to include transgender identity, because data sets that do are few and far between.\r\nBibliography\r\nBailey, L., J. Ellis, S., & McNeil, J. (2014). Suicide risk in the UK trans population and the role of gender transition in decreasing suicidal ideation and suicide attempt. Mental Health Review Journal, 19(4), 209-220. doi:10.1108/MHRJ-05-2014-0015\r\nBrenick, A., Romano, K., Kegler, C., & Eaton, L. A. (2017). Understanding the influence of stigma and medical mistrust on engagement in routine healthcare among Black women who have sex with women. LGBT Health. https://doi.org/10.1089/lgbt.2016.0083\r\nFlores, M., Watson, L., Allen, L., Ford, M., Serpe, C., Choo, P., & Farrell, M. (2018). Transgender people of color’s experiences of sexual objectification: Locating sexual objectification within a matrix of domination. Journal of Counseling Psychology, 65(3), 308-323. doi:10.1037/cou0000279\r\nGoldenberg, T., Jadwin-Cakmak, L., Popoff, E., Reisner, S. L., Campbell, B. A., & Harper, G. W. (2019). Stigma, gender affirmation, and primary healthcare use among Black transgender youth. Journal of Adolescent Health. https://doi.org/10.1016/j.jadohealth.2019.04.029\r\nHaas, A., Rodgers, P., & Herman, J. (2014). Suicide attempts among transgender and gender non-conforming adults: Findings of the national transgender discrimination survey. The Williams Institute.\r\nMcDowell, M., Hughto, J., & Reisner, S. (2019). Risk and protective factors for mental health morbidity in a community sample of female-to-male trans-masculine adults. Bmc Psychiatry, 19(1), 16-16. doi:10.1186/s12888-018-2008-0\r\n\r\n\r\n\r\n",
    "preview": "capstones/Bayesian Statistics/Bayesian-Statistcs_files/figure-html5/unnamed-chunk-10-1.png",
    "last_modified": "2022-02-24T12:21:19-06:00",
    "input_file": {}
  },
  {
    "path": "capstones/Causal Inference/",
    "title": "Causal Effect between Sleeping Time and Life Satisfaction",
    "description": "Causal Inference",
    "author": [
      {
        "name": "Yunyang Zhong",
        "url": {}
      }
    ],
    "date": "2021-12-14",
    "categories": [],
    "contents": "\r\nSlides\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-12-16T10:18:36-06:00",
    "input_file": {}
  },
  {
    "path": "capstones/Mathematical Statistics/",
    "title": "Shrinkage Methods",
    "description": "Mathematical Statistics",
    "author": [
      {
        "name": "Yunyang Zhong",
        "url": {}
      }
    ],
    "date": "2021-12-14",
    "categories": [],
    "contents": "\r\nSlides\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-12-16T10:20:11-06:00",
    "input_file": {}
  },
  {
    "path": "capstones/Survival Analysis/",
    "title": "How Long after Founding Does a Company Go Public",
    "description": "Survival Analysis",
    "author": [
      {
        "name": "Yunyang Zhong",
        "url": {}
      }
    ],
    "date": "2021-12-14",
    "categories": [],
    "contents": "\r\nSlides\r\n\r\n\r\n\r\n",
    "preview": {},
    "last_modified": "2021-12-16T10:18:54-06:00",
    "input_file": {}
  }
]
